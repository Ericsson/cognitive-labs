<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="/cognitive-labs/preview/pr-2/feed.xml" rel="self" type="application/atom+xml" /><link href="/cognitive-labs/preview/pr-2/" rel="alternate" type="text/html" /><updated>2025-07-16T13:08:41+00:00</updated><id>/cognitive-labs/preview/pr-2/feed.xml</id><title type="html">Ericsson Cognitive Labs</title><subtitle>Ericsson Cognitive Labs, opening our AI Research to the world</subtitle><entry><title type="html">Framework-Agnostic Libraries are needed</title><link href="/cognitive-labs/preview/pr-2/2025/07/16/framework-agnostic-blogy.html" rel="alternate" type="text/html" title="Framework-Agnostic Libraries are needed" /><published>2025-07-16T00:00:00+00:00</published><updated>2025-07-16T13:06:40+00:00</updated><id>/cognitive-labs/preview/pr-2/2025/07/16/framework-agnostic-blogy</id><content type="html" xml:base="/cognitive-labs/preview/pr-2/2025/07/16/framework-agnostic-blogy.html"><![CDATA[<p>Deep learning has grown fast, <em>really fast</em>. It’s now a major part of how companies make decisions and design products. With this boom, AI has become more powerful, but also way more complex. One big challenge? The explosion of tools and frameworks. We’re now living in a world full layers of complexity to build on top of backends<sup id="fnref:1"><a href="#fn:1" class="footnote" rel="footnote" role="doc-noteref">1</a></sup>. Diverse frameworks are coexisting such as TensorFlow, PyTorch, JAX, MXNet, and more, each with its own quirks and tradeoffs.</p>

<p>For machine learning engineers, it’s like walking through a forest where every path leads to a different framework, and no one’s really sure which one will still exist in five years.</p>

<h2 id="so-whats-the-issue">So, what’s the issue?</h2>

<p>These days, building AI-powered products isn’t optional — it’s expected <sup id="fnref:2"><a href="#fn:2" class="footnote" rel="footnote" role="doc-noteref">2</a></sup>. And as demand grows, so do the tools. The result? A tangled mess of components, many of which depend heavily on the framework they’re built in. There is no fault to be found as it’s natural when a field moves fast, but it’s messy and unpractical.</p>

<p>You might think, “Well, that’s just how it goes,” but here’s the thing: frameworks have a life of their own. And if you’ve ever been stuck with a deprecated tool or spent weeks porting models between frameworks, you know how painful that can get.</p>

<p>(Here’s a quick reminder of how these trends have changed over time)</p>

<!-- Google Trends embed remains here -->
<script type="text/javascript" src="https://ssl.gstatic.com/trends_nrtr/4031_RC01/embed_loader.js"></script>
<script type="text/javascript"> trends.embed.renderExploreWidget("TIMESERIES", {"comparisonItem":[{"keyword":"/g/11gd3905v1","geo":"","time":"2014-01-01 2025-04-29"},{"keyword":"/g/11bwp1s2k3","geo":"","time":"2014-01-01 2025-04-29"},{"keyword":"/m/0h95mh8","geo":"","time":"2014-01-01 2025-04-29"},{"keyword":"/g/11t6my1_gw","geo":"","time":"2014-01-01 2025-04-29"}],"category":0,"property":""}, {"exploreQuery":"date=2014-01-01%202025-04-29&q=%2Fg%2F11gd3905v1,%2Fg%2F11bwp1s2k3,%2Fm%2F0h95mh8,%2Fg%2F11t6my1_gw&hl=en-GB","guestPath":"https://trends.google.com:443/trends/embed/"}); </script>

<h2 id="the-ever-shifting-framework-landscape">The Ever-Shifting Framework Landscape</h2>

<p>Frameworks aren’t static. Some evolve (like TensorFlow 2), others fade away (remember Theano?), and new ones (like JAX) pop up with killer features. Each has its own execution style, APIs, and toolchains; and that means a steep learning curve every time you switch.</p>

<p>This complexity is a real blocker. In fact, over 90% of companies plan to ramp up their AI investments, but only 1% think their AI capabilities are where they should be. One possible reason? Fragmentation at the foundation, in other words, right at the framework level.</p>

<p>Different teams want different things. Researchers love PyTorch for fast prototyping. JAX shines in large-scale parallel computing. TensorFlow dominates in production and mobile deployments. And if you’re trying to blend open-source models into production systems, it gets even trickier. You end up mixing and matching frameworks, and unfortunetly sometimes within the same product.</p>

<h2 id="why-this-hurts-more-than-you-think">Why This Hurts (More Than You Think)</h2>

<p>When your tech stack is tied tightly to one framework, you run into problems:</p>

<ul>
  <li>
    <p><strong>Lock-in is real.</strong> If a library loses support (like Theano) or shifts direction (like TensorFlow 1 to 2), your whole system might be at risk. Building on top of multi-backend tools gives you some insurance.</p>
  </li>
  <li>
    <p><strong>Best tool for the job? Not always easy.</strong> Some frameworks do things better than others: physics simulations, distributed training, edge deployments. A rigid stack limits your options.</p>
  </li>
  <li>
    <p><strong>Reproducibility gets tricky.</strong> Even porting models between major libraries (PyTorch to ONNX, TF to JAX) can be a pain. Things like random seeds, execution modes, tensor shapes, or custom gradients often break silently.</p>
  </li>
  <li>
    <p><strong>Deploying models is harder than it should be.</strong>  AI models don’t live in one place. They train in the cloud, run on edge devices, serve millions in real-time. Framework-agnostic formats like ONNX or SavedModel make this easier—but only if you design for it.</p>
  </li>
</ul>

<h2 id="whats-the-fix-framework-agnostic--multi-framework-approaches">What’s the Fix? Framework-Agnostic &amp; Multi-Framework Approaches</h2>

<p>Instead of betting on a single framework, more teams are designing tools and workflows that work across multiple. That’s the move: <em>framework-agnostic development</em>. Here’s what that looks like:</p>

<ul>
  <li><strong>Use high-level libraries that support multiple backends.</strong> Think: Keras 3.0. One model definition, works on TensorFlow, JAX, or PyTorch.</li>
  <li><strong>Model formats like ONNX.</strong> Export once, run it wherever.</li>
  <li><strong>Testing frameworks that compare behavior across libraries.</strong> Think: differential testing to catch subtle differences.</li>
  <li><strong>Interop-focused projects.</strong> OpenXLA is a good example : it’s a shared compiler backend supported by Google that works across TF, JAX, and now PyTorch (via Torch XLA).</li>
</ul>

<p>This shift is happening gradually. PyTorch and TensorFlow are even borrowing ideas from each other. TF2 got eager execution from PyTorch, and PyTorch 2.0 added <code class="language-plaintext highlighter-rouge">torch.compile</code> (similar to how XLA optimizes graphs in TF or JAX). These aren’t just nice features, they’re steps toward a shared ecosystem.</p>

<h2 id="examples-in-the-wild">Examples in the Wild</h2>

<ul>
  <li><a href="https://keras.io/keras_3/">Keras 3.0</a>: Write code once, run on TF, JAX, or PyTorch.</li>
  <li><strong>ONNX Runtime</strong>: Load and run models on anything from CPUs to mobile to cloud GPUs.</li>
  <li><strong>Hugging Face Diffusers</strong>: Train or use generative models with either PyTorch or TensorFlow.</li>
  <li><strong>Flower</strong>: A federated learning framework that abstracts backend differences.</li>
</ul>

<!-- Landscape embed view -->
<p>But this few examples, are still lacking in comparizon with how big the deep learning ecosystem is becoming, as it can be seen on the snapshot of the open-sourced deep learning ecosystem <sup id="fnref:3"><a href="#fn:3" class="footnote" rel="footnote" role="doc-noteref">3</a></sup>.</p>
<iframe src="https://landscape.lfaidata.foundation/embed/embed.html?base-path=&amp;classify=category&amp;key=deep-learning&amp;headers=true&amp;category-header=true&amp;category-in-subcategory=false&amp;title-uppercase=false&amp;title-alignment=left&amp;title-font-family=sans-serif&amp;title-font-size=13&amp;style=shadowed&amp;bg-color=%2319006d&amp;fg-color=%23ffffff&amp;item-modal=false&amp;item-name=false&amp;size=md&amp;items-alignment=left" style="width:100%;height:600px;display:block;border:none;"></iframe>

<p><em>The snapshot has a big representation of what it is nowadays, but there are even more missing, as example go into one of the three main Frameworks, and look at their own high-level libraries<sup id="fnref:4"><a href="#fn:4" class="footnote" rel="footnote" role="doc-noteref">4</a></sup></em></p>

<h2 id="but-its-not-easy">But… It’s Not Easy</h2>

<p>As great as framework-agnostic sounds, making it work is tough.</p>

<ul>
  <li>Different frameworks handle things like tensor ops, devices, or gradients in <em>very</em> different ways.</li>
  <li>PyTorch is dynamic, JAX is functional and stateless, and TF… well, depends on the version.</li>
</ul>

<table>
  <thead>
    <tr>
      <th>Feature</th>
      <th>PyTorch</th>
      <th>TensorFlow</th>
      <th>JAX</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Default shape format</td>
      <td>NCHW</td>
      <td>NHWC</td>
      <td>NHWC</td>
    </tr>
    <tr>
      <td>Device placement</td>
      <td>Explicit (<code class="language-plaintext highlighter-rouge">.to(device)</code>)</td>
      <td>Implicit (Graph or <code class="language-plaintext highlighter-rouge">.device</code>)</td>
      <td>Functional (<code class="language-plaintext highlighter-rouge">jax.device_put</code>)</td>
    </tr>
    <tr>
      <td>Requires gradient?</td>
      <td><code class="language-plaintext highlighter-rouge">requires_grad=True</code></td>
      <td><code class="language-plaintext highlighter-rouge">tf.GradientTape()</code> context</td>
      <td><code class="language-plaintext highlighter-rouge">jax.grad()</code> functional API</td>
    </tr>
    <tr>
      <td>Mutability</td>
      <td>Mutable tensors</td>
      <td>Usually mutable</td>
      <td>Immutable (<code class="language-plaintext highlighter-rouge">pure functions</code>)</td>
    </tr>
    <tr>
      <td>Randomness</td>
      <td>Global RNG</td>
      <td>Graph seed / local seed</td>
      <td>Explicit PRNGKey</td>
    </tr>
  </tbody>
</table>

<ul>
  <li>Writing one model that works across all three? Possible, but fragile, complex, and possible very restrictive.</li>
</ul>

<p>As it can be seen, the difference in coding structure is not only the library but also the abstraction of the objects.</p>

<!-- Include this once in your base layout (if not already present) -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css" />

<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>

<script>hljs.highlightAll();</script>

<!-- Three-column comparison layout -->
<div style="display: flex; gap: 16px; flex-wrap: wrap; justify-content: space-between; margin-top: 2rem;">

  <!-- PyTorch -->
  <div style="flex: 0.5; min-width: 100px;">
    <h5>PyTorch</h5>
    <pre><code class="language-python">
import torch.nn as nn

class TorchModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.fc = nn.Linear(32, 10)

    def forward(self, x):
        return self.fc(x)
    </code></pre>
  </div>

  <!-- JAX -->
  <div style="flex: 0.5; min-width: 100px;">
    <h5>JAX (Flax)</h5>
    <pre><code class="language-python">
import flax.linen as nn

class JAXModel(nn.Module):
    @nn.compact
    def __call__(self, x):
        return nn.Dense(10)(x)
    </code></pre>
  </div>

  <!-- Agnostic -->
  <div style="flex: 0.5; min-width: 100px;">
    <h5>Framework-Agnostic</h5>
    <pre><code class="language-python">
def linear(x, w, b):
    return x @ w + b
    </code></pre>
  </div>

</div>

<p>So, multi-framework support is often the compromise. You used to write framework-specific code and sometimes even in parallel; but now you’re maintaining N versions of the same functionality, that’s a simulatenous development, testing and deployment needed for N codes. That’s a recipe for bugs. Automated testing and good abstractions are a must here, and that still requieres more effort.</p>

<p>Luckily, tool support is growing<sup id="fnref:5"><a href="#fn:5" class="footnote" rel="footnote" role="doc-noteref">5</a></sup>. There’s active research into model verification, bug detection, and better conversion tools. As the community embraces this direction, the ecosystem becomes more robust.</p>

<h2 id="where-were-headed">Where We’re Headed</h2>

<p>The ideal? A world where ML engineers can <em>write once, run anywhere</em> — whether that’s on a cloud GPU, an iPhone, or an embedded chip in a robot. We’re not fully there yet, but between open compilers (like OpenXLA), standardized formats (like ONNX), and high-level libraries (like Keras 3), we’re getting closer, and as of now hoping for smooth plug-and-play integration regardless of you  initial framework selection is a coming step.</p>

<p>If your team is building anything meant to last more than a couple years, thinking about framework-agnostic design early on can save you a lot of pain later.</p>

<p>Let’s build for the long term — even if the frameworks keep changing under our feet.</p>

<hr />

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1">
      <p>The well known landscape of dependencies for a ML System, <a href="https://papers.nips.cc/paper_files/paper/2015/hash/86df7dcfd896fcaf2674f757a2463eba-Abstract.html">Hidden Technical Debt in Machine Learning Systems</a>, is futher expanded with other papers such as <a href="https://arxiv.org/pdf/2409.11826">A Taxonomy of Self-Admitted Technical Debt in Deep Learning Systems</a> which found that i) there is a significant number of technical debt in all the studied deep learning frameworks. ii) there is design debt, defect debt, documentation debt, test debt, requirement debt, compatibility debt, and algorithm debt in deep learning frameworks. iii) the majority of the technical debt in deep learning framework is design debt (24.07% - 65.27%), followed by requirement debt (7.09% - 31.48%) and algorithm debt (5.62% - 20.67%). In some projects, compatibility debt accounts for more than 10%. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2">
      <p>According to <a href="https://www.mckinsey.com/capabilities/quantumblack/our-insights/the-state-of-ai" title="Mckinsey: Global Survey on the State of AI, 2025">Mckinsey global survey</a> on the corporation view of AI, deep learning and artificial intelligence are integrated into at least one business function by 78% of respondents. <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:3">
      <p>As noted by McKinsey’s<a href="https://deepmind.google/discover/blog/using-jax-to-accelerate-our-research/">Open Source in the Age of AI (2023)</a>, around 92% of companies reported that they use open-source software in at least one of their AI initiatives. The survey also highlights that open-source components are increasingly critical not just for research prototyping, but also for production deployments in enterprise settings. The landscap of only deep learning open sourced by Linux Foundation, <a href="https://lfai.landscape2.io/">Open-Source Ecosystem for Machine Learning by the Linux Foundation</a>, but out there exists many more if you go to other libraries layers such as in backends / data / security / ethics / model / deployment … managers. <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:4">
      <p>Examples include: i) The ecosystem built over PyTorch: PyTorch Geometric, TorchText, TorchAudio, and third-party libraries like Pyro and Stable Baselines 3 (SB3). ii) The TensorFlow ecosystem: APIs like TensorFlow Lite, TFX, TensorFlow.js, and extensions such as TensorFlow Probability, TensorFlow GNN, and TensorFlow Quantum (plus projects like Sonnet). iii) Other frameworks: Stable Baselines (SB3) is building SBX for reinforcement learning with JAX or <a href="https://deepmind.google/discover/blog/using-jax-to-accelerate-our-research/">Google DeepMind’s libraries</a> including dm-haiku (neural networks), MCTX (Monte Carlo tree search), Jraph (graph neural networks), and physics simulators like JAX MD. <a href="#fnref:4" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:5">
      <p>One recent paper on DL testing [Deep Learning Library Testing: Definition, Methods, and Challenges][3] Survey with 93 papers collected from the literature, where 69 are related to DL framework testing, 12 to DL compiler testing and 13 to DL hardware library testing. There exists a recent trend with more papers on this topic. <a href="#fnref:5" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>]]></content><author><name>lucia-ferrer</name></author><category term="Software" /><category term="Framework-agnostic" /><summary type="html"><![CDATA[Deep learning has grown fast, really fast. It’s now a major part of how companies make decisions and design products. With this boom, AI has become more powerful, but also way more complex. One big challenge? The explosion of tools and frameworks. We’re now living in a world full layers of complexity to build on top of backends1. Diverse frameworks are coexisting such as TensorFlow, PyTorch, JAX, MXNet, and more, each with its own quirks and tradeoffs.]]></summary></entry><entry><title type="html">The Cognitive Labs Blog</title><link href="/cognitive-labs/preview/pr-2/2025/07/06/ericsson-labs-blog.html" rel="alternate" type="text/html" title="The Cognitive Labs Blog" /><published>2025-07-06T00:00:00+00:00</published><updated>2025-07-16T13:06:40+00:00</updated><id>/cognitive-labs/preview/pr-2/2025/07/06/ericsson-labs-blog</id><content type="html" xml:base="/cognitive-labs/preview/pr-2/2025/07/06/ericsson-labs-blog.html"><![CDATA[<p>It is not new the idea of making a blog so, why now? What does it mean? And most important, what is this about?</p>

<p>Six months ago, we released our new initiative to contribute to the open-source community by creating the Ericsson Cognitive Labs. We believed that since we are working in cutting-edge technology, such as Graph Neural Networks or Explainability, our research can benefit the community, having the possibility of applying it in fields such as medicine, autonomous driving, or drug discovery. The idea was bringing these ideas closer to the community and contributing to the open-source ecosystem to give back to the community. However, we have noted that sometimes academic papers, even if they bring an implementation with them, only reach a small audience.</p>

<p>To solve that, we have decided to bring a new idea to the table and make a technical blog. Many of you will know for sure the <a href="https://www.ericsson.com/en/blog">Ericsson Blog</a>, where Ericsson projects are announced and discussed, but here our objective is completely different. As a result, our goal is to make our research more readily available, reaching a larger audience than a paper alone, and creating articles about specific implementations (sometimes with significant efficiency savings) that might not be appropriate for a journal or conference.</p>

<p>More specifically, we plan to add content in the following areas:</p>

<ul>
  <li>
    <p>Bring AI research closer. There may be areas that are not as popular as the famous Large Language Models (LLMs), and one can find only little information about them. Moreover, these areas are usually only known in the academic world, with almost no information available outside these types of circles. Our first objective is to provide content about these AI topics, bringing them closer to the public so they can be used by anyone.</p>
  </li>
  <li>
    <p>Deep dive into the software part of our research. We have the feeling that we always share the results of our experiments, which are extensively discussed in our papers, but never about the implementation or how to make research efficient. Even when sometimes we believe that the most interesting part of a problem is how to make it efficient and scalable.</p>
  </li>
  <li>
    <p>Discussion about new technologies and methodologies in the AI industry. We also believe that it may be helpful to be fully open and transparent about what technologies we use, starting new discussions about the possible tech stack and how the industry is evolving.</p>
  </li>
</ul>

<p>What we have explained is not new, and we have been inspired by amazing companies such as <a href="https://deepmind.google/">Google DeepMind</a>, <a href="https://ai.meta.com/research/">Meta FAIR</a> or <a href="https://www.modular.com/blog/">Modular</a>, and we want to take this idea one level further. Therefore, this will be not only to talk briefly about our projects or new trends but also a new channel to be able to share parts of our research that do not fit into more classic channels, such as conferences or journals. We are happy to share and contribute to this amazing industry. Stay tuned for more!</p>]]></content><author><name>oscar-llorente-gonzalez, lucia-ferrer, antonio-diaz, dani-bazo, alvaro, sangam</name></author><category term="community" /><summary type="html"><![CDATA[To continue our effort to contribute to the open-source community we would like to present the Cognitive Labs Blog, our new channel to communicate about the research we are doing, trying to bring closer our technology to the public.]]></summary></entry></feed>