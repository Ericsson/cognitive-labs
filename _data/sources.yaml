- id: doi:10.1007/978-3-031-63787-2_20
  date: '2024-07-10'
  type: paper
  image: images/papers/light.jpg
  authors:
  - Oscar Llorente Gonzalez
  - Rana Fawzy
  - Jared keown
  - Michal Horemuz
  - "P\xE9ter Vaderna"
  - "S\xE1ndor Laki"
  - "Roland Kotrocz\xF3"
  - Rita Csoma
  - "J\xE1nos M\xE1rk Szalai-Gindl"
  description: Explainability in Graph Neural Networks (GNNs) is a new field growing in the last few years. In this publication we address the problem of determining how important is each neighbor for the GNN when classifying a node and how to measure the performance for this specific task. To do this, various known explainability methods are reformulated to get the neighbor importance and four new metrics are presented. Our results show that there is almost no difference between the explanations provided by gradient-based techniques in the GNN domain. In addition, many explainability techniques failed to identify important neighbors when GNNs without self-loops are used.
  publisher: xAI
  tags:
  - GAI Lab
  - Ericsson GAIA
  - Ericsson Research
  buttons:
  - type: paper
    text: Manuscript
    link: https://link.springer.com/chapter/10.1007/978-3-031-63787-2_20
  - type: github
    text: Source Code
    link: EricssonResearch/gnn-neighbors-xai

- id: doi:10.48550/arXiv.2310.19573
  date: '2023-10-30'
  type: paper
  image: images/papers/night.jpg
  authors:
  - Sharath M Shankaranarayana
  description: Supervised machine learning relies on the availability of good labelled data for model training. Labelled data is acquired by human annotation, which is a cumbersome and costly process, often requiring subject matter experts. Active learning is a sub-field of machine learning which helps in obtaining the labelled data efficiently by selecting the most valuable data instances for model training and querying the labels only for those instances from the human annotator. Recently, a lot of research has been done in the field of active learning, especially for deep neural network based models. Although deep learning shines when dealing with image\textual\multimodal data, gradient boosting methods...
  buttons:
  - type: paper
    text: Manuscript
    link: https://arxiv.org/abs/2310.19573


- id: doi:10.48550/arXiv.2309.12913

  date: '2023-09-22'
  type: paper
  image: images/papers/space.jpg
  authors:
  - Oscar Llorente Gonzalez
  - Jaime Boal
  - Eugenio F. Sánchez-Úbeda
  description: ESaliency maps have become one of the most widely used interpretability techniques for convolutional neural networks (CNN) due to their simplicity and the quality of the insights they provide. However, there are still some doubts about whether these insights are a trustworthy representation of what CNNs use to come up with their predictions. This paper explores how rescuing the sign of the gradients from the saliency map can lead to a deeper understanding of multi-class classification problems. Using both pretrained and trained from scratch CNNs we unveil that considering the sign and the effect not only of the correct class, but also the influence of the other classes, allows to better identify the pixels of the image that the network is really focusing on. Furthermore, how occluding or altering those pixels is expected to affect the outcome also becomes clearer.
  tags:
  - GAI Lab
  - Comillas Pontifical University (ICAI)
  buttons:
  - type: paper
    text: Manuscript
    link: https://arxiv.org/abs/2309.12913
  - type: github
    text: Source Code
    link: osllogon/positive_active_saliency_maps


- id: doi:10.48550/arXiv.2302.12899

  date: '2023-05-24'
  type: paper
  image: images/papers/cloud_city.jpg
  authors:
  - Adriano Mendo
  - Jose Outes-Carnero
  - Yak Ng-Molina
  - Juan Ramiro-Moreno
  description: This paper presents a method for optimizing wireless networks by adjusting cell parameters that affect both the performance of the cell being optimized and the surrounding cells. The method uses multiple reinforcement learning agents that share a common policy and take into account information from neighboring cells to determine the state and reward. In order to avoid impairing network performance during the initial stages of learning, agents are pre-trained in an earlier phase of offline learning. During this phase, an initial policy is obtained using feedback from a static network simulator and considering a wide variety of scenarios. Finally, agents can intelligently tune the cell parameters of a test network by suggesting small incremental changes, slowly guiding the network toward an optimal configuration. The agents propose optimal changes using the experience gained with the simulator in the pre-training phase, but they can also continue to learn from current network readings after each change. The results show how the proposed approach significantly improves the performance gains already provided by expert system-based methods when applied to remote antenna tilt optimization. The significant gains of this approach have truly been observed when compared with a similar method in which the state and reward do not incorporate information from neighboring cells.
  publisher: IAENG-IJCS
  buttons:
  - type: paper
    text: Manuscript
    link: https://www.iaeng.org/IJCS/issues_v50/issue_3/IJCS_50_3_08.pdf
