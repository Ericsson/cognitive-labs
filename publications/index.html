<!DOCTYPE html>
<html lang="en" data-dark="false">
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <!--
  put your analytics (e.g. Google Analytics) tracking code here
-->

  <!--
  put your search engine verification (e.g. Google Search Console) tag here
-->

  


























<meta name="viewport" content="width=device-width, initial-scale=1">

<title>Publications | Cognitive Labs - Ericsson</title>

<link rel="icon" href="/cognitive-labs/images/logo_small.png">

<meta name="title" content="Publications">
<meta name="description" content="Ericsson Cognitive Labs, opening our AI Research to the world">

<meta property="og:title" content="Publications">
<meta property="og:site_title" content="Cognitive Labs - Ericsson">
<meta property="og:description" content="Ericsson Cognitive Labs, opening our AI Research to the world">
<meta property="og:url" content="">
<meta property="og:image" content="/cognitive-labs/images/logo_small.png">
<meta property="og:locale" content="en_US">

<meta property="twitter:title" content="Publications">
<meta property="twitter:description" content="Ericsson Cognitive Labs, opening our AI Research to the world">
<meta property="twitter:url" content="">
<meta property="twitter:card" content="summary_large_image">
<meta property="twitter:image" content="/cognitive-labs/images/logo_small.png">


  <meta property="og:type" content="website">


<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "WebSite",
    
    "name": "Publications",
    "description": "Ericsson Cognitive Labs, opening our AI Research to the world",
    "headline": "Publications",
    "publisher": {
      "@type": "Organization",
      "logo": { "@type": "ImageObject", "url": "/cognitive-labs/images/logo_small.png" }
    },
    "url": ""
  }
</script>

<link rel="alternate" type="application/rss+xml" href="/cognitive-labs/feed.xml">

  <!-- Google Fonts -->
<!-- automatically get url from fonts used in theme file -->

<link rel="preconnect" href="https://fonts.gstatic.com">
<link href="https://fonts.googleapis.com/css2?display=swap&&family=Roboto+Mono:ital,wght@0,200;0,400;0,500;0,600;1,200;1,400;1,500;1,600&amp;family=ericsson:ital,wght@0,200;0,400;0,500;0,600;1,200;1,400;1,500;1,600" rel="stylesheet">

<!-- Font Awesome icons (load asynchronously due to size) -->

<link href="https://use.fontawesome.com/releases/v6.4.2/css/all.css" rel="preload" as="style" onload="this.onload = null; this.rel = 'stylesheet';">
<noscript>
  <link href="https://use.fontawesome.com/releases/v6.4.2/css/all.css" rel="stylesheet">
</noscript>

  <!-- third party styles -->
<!-- https://stylishthemes.github.io/Syntax-Themes/pygments/ -->
<link href="https://cdn.jsdelivr.net/gh/StylishThemes/Syntax-Themes/pygments/css-github/pygments-tomorrow-night-eighties.css" rel="stylesheet">

<!-- include all sass in styles folder -->


  
    <link href="/cognitive-labs/_styles/-theme.css" rel="stylesheet">
  

  
    <link href="/cognitive-labs/_styles/alert.css" rel="stylesheet">
  

  
    <link href="/cognitive-labs/_styles/all.css" rel="stylesheet">
  

  
    <link href="/cognitive-labs/_styles/anchor.css" rel="stylesheet">
  

  
    <link href="/cognitive-labs/_styles/background.css" rel="stylesheet">
  

  
    <link href="/cognitive-labs/_styles/body.css" rel="stylesheet">
  

  
    <link href="/cognitive-labs/_styles/bold.css" rel="stylesheet">
  

  
    <link href="/cognitive-labs/_styles/button.css" rel="stylesheet">
  

  
    <link href="/cognitive-labs/_styles/card.css" rel="stylesheet">
  

  
    <link href="/cognitive-labs/_styles/checkbox.css" rel="stylesheet">
  

  
    <link href="/cognitive-labs/_styles/citation.css" rel="stylesheet">
  

  
    <link href="/cognitive-labs/_styles/code.css" rel="stylesheet">
  

  
    <link href="/cognitive-labs/_styles/cols.css" rel="stylesheet">
  

  
    <link href="/cognitive-labs/_styles/dark-toggle.css" rel="stylesheet">
  

  
    <link href="/cognitive-labs/_styles/feature.css" rel="stylesheet">
  

  
    <link href="/cognitive-labs/_styles/figure.css" rel="stylesheet">
  

  
    <link href="/cognitive-labs/_styles/float.css" rel="stylesheet">
  

  
    <link href="/cognitive-labs/_styles/font.css" rel="stylesheet">
  

  
    <link href="/cognitive-labs/_styles/footer.css" rel="stylesheet">
  

  
    <link href="/cognitive-labs/_styles/form.css" rel="stylesheet">
  

  
    <link href="/cognitive-labs/_styles/grid.css" rel="stylesheet">
  

  
    <link href="/cognitive-labs/_styles/header.css" rel="stylesheet">
  

  
    <link href="/cognitive-labs/_styles/heading.css" rel="stylesheet">
  

  
    <link href="/cognitive-labs/_styles/highlight.css" rel="stylesheet">
  

  
    <link href="/cognitive-labs/_styles/icon.css" rel="stylesheet">
  

  
    <link href="/cognitive-labs/_styles/image.css" rel="stylesheet">
  

  
    <link href="/cognitive-labs/_styles/link.css" rel="stylesheet">
  

  
    <link href="/cognitive-labs/_styles/list.css" rel="stylesheet">
  

  
    <link href="/cognitive-labs/_styles/main.css" rel="stylesheet">
  

  
    <link href="/cognitive-labs/_styles/paragraph.css" rel="stylesheet">
  

  
    <link href="/cognitive-labs/_styles/portrait.css" rel="stylesheet">
  

  
    <link href="/cognitive-labs/_styles/post-excerpt.css" rel="stylesheet">
  

  
    <link href="/cognitive-labs/_styles/post-info.css" rel="stylesheet">
  

  
    <link href="/cognitive-labs/_styles/post-nav.css" rel="stylesheet">
  

  
    <link href="/cognitive-labs/_styles/quote.css" rel="stylesheet">
  

  
    <link href="/cognitive-labs/_styles/rule.css" rel="stylesheet">
  

  
    <link href="/cognitive-labs/_styles/search-box.css" rel="stylesheet">
  

  
    <link href="/cognitive-labs/_styles/search-info.css" rel="stylesheet">
  

  
    <link href="/cognitive-labs/_styles/section.css" rel="stylesheet">
  

  
    <link href="/cognitive-labs/_styles/table.css" rel="stylesheet">
  

  
    <link href="/cognitive-labs/_styles/tags.css" rel="stylesheet">
  

  
    <link href="/cognitive-labs/_styles/textbox.css" rel="stylesheet">
  

  
    <link href="/cognitive-labs/_styles/tooltip.css" rel="stylesheet">
  

  
    <link href="/cognitive-labs/_styles/util.css" rel="stylesheet">
  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  


<!-- include all css in styles folder -->



  <!-- third party scripts -->
<script src="https://unpkg.com/@popperjs/core@2" defer></script>
<script src="https://unpkg.com/tippy.js@6" defer></script>
<script src="https://unpkg.com/mark.js@8" defer></script>

<!-- include all js in scripts folder -->


  <script src="/cognitive-labs/_scripts/anchors.js"></script>

  <script src="/cognitive-labs/_scripts/dark-mode.js"></script>

  <script src="/cognitive-labs/_scripts/fetch-tags.js"></script>

  <script src="/cognitive-labs/_scripts/search.js"></script>

  <script src="/cognitive-labs/_scripts/site-search.js"></script>

  <script src="/cognitive-labs/_scripts/tooltip.js"></script>


</head>

  <body>
    







<header class="background" style="--image: url('/cognitive-labs/images/ericsson_background.jpg')" data-dark="true">
  <a href="/cognitive-labs/" class="home">
    
      <span class="logo">
        
          <img src="/cognitive-labs/images/logo.png" alt="logo">
        
      </span>
    
    
      <span class="title" data-tooltip="Home">
        
          <span>Ericsson Cognitive Labs</span>
        
        
      </span>
    
  </a>

  <input class="nav-toggle" type="checkbox" aria-label="show/hide nav">

  <nav>
    
    
      
        <a href="/cognitive-labs/publications/" data-tooltip="Published works">
          Publications
        </a>
      
    
      
        <a href="/cognitive-labs/labs/" data-tooltip="Our research organization">
          Labs
        </a>
      
    
      
        <a href="/cognitive-labs/team/" data-tooltip="About our team">
          Team
        </a>
      
    
      
        <a href="/cognitive-labs/blog/" data-tooltip="Our insights">
          Blog
        </a>
      
    
      
        <a href="/cognitive-labs/contact/" data-tooltip="Email, address, and location">
          Contact
        </a>
      
    
  </nav>
</header>

    <main>
      <!--
  modify main content of page:
  - add section breaks
  - attach section properties
  - wrap each table in div to allow for scrolling
  - filter out blank sections
-->








  
  
  

  <section class="background" data-size="page">
    <h1 id="-publications">
<i class="icon fa-solid fa-scroll"></i> Publications</h1>

<p>On this page, all the publications from Ericsson Cognitive Labs are listed, with links to the manuscript and the code to ensure reproducibility. We have also provided tags, so you can check our collaborators for each publication.</p>

<h2 id="highlighted">Highlighted</h2>

<div class="citation">
  
    <a href="https://doi.org/10.1007/978-3-031-63787-2_20" class="citation-image" aria-label="Evaluating Neighbor Explainability for Graph Neural Networks">
      <img src="/cognitive-labs/images/papers/light.jpg" alt="Evaluating Neighbor Explainability for Graph Neural Networks" loading="lazy" onerror="this.src = '/cognitive-labs/images/fallback.svg'; this.onerror = null;">
    </a>
  

  <div class="citation-text">
    
    <i class="icon fa-solid fa-scroll"></i>

    <a href="https://doi.org/10.1007/978-3-031-63787-2_20" class="citation-title">
      Evaluating Neighbor Explainability for Graph Neural Networks
    </a>

    <div class="citation-authors" tabindex="0">
      Oscar Llorente Gonzalez, Rana Fawzy, Jared keown, Michal Horemuz, Péter Vaderna, Sándor Laki, Roland Kotroczó, Rita Csoma, János Márk Szalai-Gindl
    </div>

    <div class="citation-details">
      xAI
        ·  
      10 Jul 2024
        ·  
      doi:10.1007/978-3-031-63787-2_20
    </div>

    
      
        <div class="citation-description">
          Explainability in Graph Neural Networks (GNNs) is a new field growing in the last few years. In this publication we address the problem of determining how important is each neighbor for the GNN when classifying a node and how to measure the performance for this specific task. To do this, various known explainability methods are reformulated to get the neighbor importance and four new metrics are presented. Our results show that there is almost no difference between the explanations provided by gradient-based techniques in the GNN domain. In addition, many explainability techniques failed to identify important neighbors when GNNs without self-loops are used.

        </div>
      

      
        <div class="citation-buttons">
          
            



  <div class="button-wrapper">
    <a class="button" href="https://link.springer.com/chapter/10.1007/978-3-031-63787-2_20" data-tooltip="Paper" data-style="bare" aria-label="Paper">
      <i class="icon fa-solid fa-scroll"></i>
      
        <span>Manuscript</span>
      
    </a>
  </div>


          
            



  <div class="button-wrapper">
    <a class="button" href="https://github.com/EricssonResearch/gnn-neighbors-xai" data-tooltip="GitHub" data-style="bare" aria-label="GitHub">
      <i class="icon fa-brands fa-github"></i>
      
        <span>Source Code</span>
      
    </a>
  </div>


          
        </div>
      

      
        


  <div class="tags" data-link="/cognitive-labs/publications/">
    
      <a href='/cognitive-labs/publications/?search="tag:%20GAI%20Lab"' class="tag" data-tooltip='Show items with the tag "GAI Lab"'>
        GAI Lab
      </a>
    
      <a href='/cognitive-labs/publications/?search="tag:%20Ericsson%20GAIA"' class="tag" data-tooltip='Show items with the tag "Ericsson GAIA"'>
        Ericsson GAIA
      </a>
    
      <a href='/cognitive-labs/publications/?search="tag:%20Ericsson%20Research"' class="tag" data-tooltip='Show items with the tag "Ericsson Research"'>
        Ericsson Research
      </a>
    
  </div>


      
    
  </div>
</div>
  </section>

  
  
  

  <section class="background" data-size="page">
    <!--
  background: ;
  dark: ;
  size: ;
-->

<h2 id="all">All</h2>

<div class="search-box">
  <input type="text" class="search-input" oninput="onSearchInput(this)" placeholder="Search items on this page">
  <button disabled data-tooltip="Clear search" aria-label="clear search" onclick="onSearchClear()">
    <i class="icon fa-solid fa-magnifying-glass"></i>
  </button>
</div>

<div class="search-info"></div>

<h3 id="2024">2024</h3>

<div class="citation">
  
    <a href="https://doi.org/10.1007/978-3-031-63787-2_20" class="citation-image" aria-label="Evaluating Neighbor Explainability for Graph Neural Networks">
      <img src="/cognitive-labs/images/papers/light.jpg" alt="Evaluating Neighbor Explainability for Graph Neural Networks" loading="lazy" onerror="this.src = '/cognitive-labs/images/fallback.svg'; this.onerror = null;">
    </a>
  

  <div class="citation-text">
    
    <i class="icon fa-solid fa-scroll"></i>

    <a href="https://doi.org/10.1007/978-3-031-63787-2_20" class="citation-title">
      Evaluating Neighbor Explainability for Graph Neural Networks
    </a>

    <div class="citation-authors" tabindex="0">
      Oscar Llorente Gonzalez, Rana Fawzy, Jared keown, Michal Horemuz, Péter Vaderna, Sándor Laki, Roland Kotroczó, Rita Csoma, János Márk Szalai-Gindl
    </div>

    <div class="citation-details">
      xAI
        ·  
      10 Jul 2024
        ·  
      doi:10.1007/978-3-031-63787-2_20
    </div>

    
      
        <div class="citation-description">
          Explainability in Graph Neural Networks (GNNs) is a new field growing in the last few years. In this publication we address the problem of determining how important is each neighbor for the GNN when classifying a node and how to measure the performance for this specific task. To do this, various known explainability methods are reformulated to get the neighbor importance and four new metrics are presented. Our results show that there is almost no difference between the explanations provided by gradient-based techniques in the GNN domain. In addition, many explainability techniques failed to identify important neighbors when GNNs without self-loops are used.

        </div>
      

      
        <div class="citation-buttons">
          
            



  <div class="button-wrapper">
    <a class="button" href="https://link.springer.com/chapter/10.1007/978-3-031-63787-2_20" data-tooltip="Paper" data-style="bare" aria-label="Paper">
      <i class="icon fa-solid fa-scroll"></i>
      
        <span>Manuscript</span>
      
    </a>
  </div>


          
            



  <div class="button-wrapper">
    <a class="button" href="https://github.com/https://github.com/EricssonResearch/gnn-neighbors-xai" data-tooltip="GitHub" data-style="bare" aria-label="GitHub">
      <i class="icon fa-brands fa-github"></i>
      
        <span>Source Code</span>
      
    </a>
  </div>


          
        </div>
      

      
        


  <div class="tags" data-link="/cognitive-labs/publications/">
    
      <a href='/cognitive-labs/publications/?search="tag:%20GAI%20Lab"' class="tag" data-tooltip='Show items with the tag "GAI Lab"'>
        GAI Lab
      </a>
    
      <a href='/cognitive-labs/publications/?search="tag:%20Ericsson%20GAIA"' class="tag" data-tooltip='Show items with the tag "Ericsson GAIA"'>
        Ericsson GAIA
      </a>
    
      <a href='/cognitive-labs/publications/?search="tag:%20Ericsson%20Research"' class="tag" data-tooltip='Show items with the tag "Ericsson Research"'>
        Ericsson Research
      </a>
    
  </div>


      
    
  </div>
</div>

<h3 id="2023">2023</h3>

<div class="citation">
  
    <a href="https://doi.org/10.48550/arxiv.2310.19573" class="citation-image" aria-label="Model Uncertainty based Active Learning on Tabular Data using Boosted Trees">
      <img src="/cognitive-labs/images/papers/night.jpg" alt="Model Uncertainty based Active Learning on Tabular Data using Boosted Trees" loading="lazy" onerror="this.src = '/cognitive-labs/images/fallback.svg'; this.onerror = null;">
    </a>
  

  <div class="citation-text">
    
    <i class="icon fa-solid fa-scroll"></i>

    <a href="https://doi.org/10.48550/arxiv.2310.19573" class="citation-title">
      Model Uncertainty based Active Learning on Tabular Data using Boosted Trees
    </a>

    <div class="citation-authors" tabindex="0">
      Sharath M Shankaranarayana
    </div>

    <div class="citation-details">
      arXiv
        ·  
      30 Oct 2023
        ·  
      doi:10.48550/arXiv.2310.19573
    </div>

    
      
        <div class="citation-description">
          Supervised machine learning relies on the availability of good labelled data for model training. Labelled data is acquired by human annotation, which is a cumbersome and costly process, often requiring subject matter experts. Active learning is a sub-field of machine learning which helps in obtaining the labelled data efficiently by selecting the most valuable data instances for model training and querying the labels only for those instances from the human annotator. Recently, a lot of research has been done in the field of active learning, especially for deep neural network based models. Although deep learning shines when dealing with image\textual\multimodal data, gradient boosting methods…

        </div>
      

      
        <div class="citation-buttons">
          
            



  <div class="button-wrapper">
    <a class="button" href="https://arxiv.org/abs/2310.19573" data-tooltip="Paper" data-style="bare" aria-label="Paper">
      <i class="icon fa-solid fa-scroll"></i>
      
        <span>Manuscript</span>
      
    </a>
  </div>


          
        </div>
      

      
    
  </div>
</div>

<div class="citation">
  
    <a href="https://doi.org/10.48550/arxiv.2309.12913" class="citation-image" aria-label="A matter of attitude: Focusing on positive and active gradients to boost saliency maps">
      <img src="/cognitive-labs/images/papers/space.jpg" alt="A matter of attitude: Focusing on positive and active gradients to boost saliency maps" loading="lazy" onerror="this.src = '/cognitive-labs/images/fallback.svg'; this.onerror = null;">
    </a>
  

  <div class="citation-text">
    
    <i class="icon fa-solid fa-scroll"></i>

    <a href="https://doi.org/10.48550/arxiv.2309.12913" class="citation-title">
      A matter of attitude: Focusing on positive and active gradients to boost saliency maps
    </a>

    <div class="citation-authors" tabindex="0">
      Oscar Llorente Gonzalez, Jaime Boal, Eugenio F. Sánchez-Úbeda
    </div>

    <div class="citation-details">
      arXiv
        ·  
      22 Sep 2023
        ·  
      doi:10.48550/arXiv.2309.12913
    </div>

    
      
        <div class="citation-description">
          ESaliency maps have become one of the most widely used interpretability techniques for convolutional neural networks (CNN) due to their simplicity and the quality of the insights they provide. However, there are still some doubts about whether these insights are a trustworthy representation of what CNNs use to come up with their predictions. This paper explores how rescuing the sign of the gradients from the saliency map can lead to a deeper understanding of multi-class classification problems. Using both pretrained and trained from scratch CNNs we unveil that considering the sign and the effect not only of the correct class, but also the influence of the other classes, allows to better identify the pixels of the image that the network is really focusing on. Furthermore, how occluding or altering those pixels is expected to affect the outcome also becomes clearer.

        </div>
      

      
        <div class="citation-buttons">
          
            



  <div class="button-wrapper">
    <a class="button" href="https://arxiv.org/abs/2309.12913" data-tooltip="Paper" data-style="bare" aria-label="Paper">
      <i class="icon fa-solid fa-scroll"></i>
      
        <span>Manuscript</span>
      
    </a>
  </div>


          
            



  <div class="button-wrapper">
    <a class="button" href="https://github.com/osllogon/positive_active_saliency_maps" data-tooltip="GitHub" data-style="bare" aria-label="GitHub">
      <i class="icon fa-brands fa-github"></i>
      
        <span>Source Code</span>
      
    </a>
  </div>


          
        </div>
      

      
        


  <div class="tags" data-link="/cognitive-labs/publications/">
    
      <a href='/cognitive-labs/publications/?search="tag:%20GAI%20Lab"' class="tag" data-tooltip='Show items with the tag "GAI Lab"'>
        GAI Lab
      </a>
    
      <a href='/cognitive-labs/publications/?search="tag:%20Comillas%20Pontifical%20University%20(ICAI)"' class="tag" data-tooltip='Show items with the tag "Comillas Pontifical University (ICAI)"'>
        Comillas Pontifical University (ICAI)
      </a>
    
  </div>


      
    
  </div>
</div>

<div class="citation">
  
    <a href="https://doi.org/10.48550/arxiv.2302.12899" class="citation-image" aria-label="Multi-Agent Reinforcement Learning with Common Policy for Antenna Tilt Optimization">
      <img src="/cognitive-labs/images/papers/cloud_city.jpg" alt="Multi-Agent Reinforcement Learning with Common Policy for Antenna Tilt Optimization" loading="lazy" onerror="this.src = '/cognitive-labs/images/fallback.svg'; this.onerror = null;">
    </a>
  

  <div class="citation-text">
    
    <i class="icon fa-solid fa-scroll"></i>

    <a href="https://doi.org/10.48550/arxiv.2302.12899" class="citation-title">
      Multi-Agent Reinforcement Learning with Common Policy for Antenna Tilt Optimization
    </a>

    <div class="citation-authors" tabindex="0">
      Adriano Mendo, Jose Outes-Carnero, Yak Ng-Molina, Juan Ramiro-Moreno
    </div>

    <div class="citation-details">
      IAENG-IJCS
        ·  
      24 May 2023
        ·  
      doi:10.48550/arXiv.2302.12899
    </div>

    
      
        <div class="citation-description">
          This paper presents a method for optimizing wireless networks by adjusting cell parameters that affect both the performance of the cell being optimized and the surrounding cells. The method uses multiple reinforcement learning agents that share a common policy and take into account information from neighboring cells to determine the state and reward. In order to avoid impairing network performance during the initial stages of learning, agents are pre-trained in an earlier phase of offline learning. During this phase, an initial policy is obtained using feedback from a static network simulator and considering a wide variety of scenarios. Finally, agents can intelligently tune the cell parameters of a test network by suggesting small incremental changes, slowly guiding the network toward an optimal configuration. The agents propose optimal changes using the experience gained with the simulator in the pre-training phase, but they can also continue to learn from current network readings after each change. The results show how the proposed approach significantly improves the performance gains already provided by expert system-based methods when applied to remote antenna tilt optimization. The significant gains of this approach have truly been observed when compared with a similar method in which the state and reward do not incorporate information from neighboring cells.

        </div>
      

      
        <div class="citation-buttons">
          
            



  <div class="button-wrapper">
    <a class="button" href="https://www.iaeng.org/IJCS/issues_v50/issue_3/IJCS_50_3_08.pdf" data-tooltip="Paper" data-style="bare" aria-label="Paper">
      <i class="icon fa-solid fa-scroll"></i>
      
        <span>Manuscript</span>
      
    </a>
  </div>


          
        </div>
      

      
    
  </div>
</div>
  </section>


    </main>
    


<footer class="background" style="--image: url('/cognitive-labs/images/ericsson_background.jpg')" data-dark="true" data-size="wide">
  <!--
    <div>
      Extra details like contact info or address
    </div>
  -->

  <div>
    
      
      
      



  <div class="button-wrapper">
    <a class="button" href="mailto:oscar.llorente.gonzalez@ericsson.com" data-tooltip="Email" data-style="bare" aria-label="Email">
      <i class="icon fa-solid fa-envelope"></i>
      
    </a>
  </div>


    
      
      
      



  <div class="button-wrapper">
    <a class="button" href="https://github.com/EricssonResearch" data-tooltip="GitHub" data-style="bare" aria-label="GitHub">
      <i class="icon fa-brands fa-github"></i>
      
    </a>
  </div>


    
      
      
      



  <div class="button-wrapper">
    <a class="button" href="https://www.linkedin.com/company/ericsson" data-tooltip="LinkedIn" data-style="bare" aria-label="LinkedIn">
      <i class="icon fa-brands fa-linkedin"></i>
      
    </a>
  </div>


    
      
      
      



  <div class="button-wrapper">
    <a class="button" href="https://youtube.com/user/ericsson" data-tooltip="YouTube" data-style="bare" aria-label="YouTube">
      <i class="icon fa-brands fa-youtube"></i>
      
    </a>
  </div>


    
      
      
      



  <div class="button-wrapper">
    <a class="button" href="https://twitter.com/ericsson" data-tooltip="Twitter" data-style="bare" aria-label="Twitter">
      <i class="icon fa-brands fa-x-twitter"></i>
      
    </a>
  </div>


    
  </div>

  <div>
    © Telefonaktiebolaget LM Ericsson 1994-2025
  </div>

</footer>

  </body>
</html>
